{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d59ac976-c57e-4b48-b20d-0602c54831ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8857b594-a2ff-4c73-b284-cf67524feded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[22]: [FileInfo(path=&#39;dbfs:/FileStore/tables/authentication_credentials.csv&#39;, name=&#39;authentication_credentials.csv&#39;, size=202, modificationTime=1687110999000)]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[22]: [FileInfo(path=&#39;dbfs:/FileStore/tables/authentication_credentials.csv&#39;, name=&#39;authentication_credentials.csv&#39;, size=202, modificationTime=1687110999000)]</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AWS cred locations\n",
    "dbutils.fs.ls(\"/FileStore/tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6554ab6d-2340-40c5-a9e1-f156cc3fb82e",
     "showTitle": true,
     "title": "Read Credentials"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify file type to be csv\n",
    "file_type = \"csv\"\n",
    "# Indicates file has first row as the header\n",
    "first_row_is_header = \"true\"\n",
    "# Indicates file has comma as the delimeter\n",
    "delimiter = \",\"\n",
    "# Read the CSV file to spark dataframe\n",
    "aws_keys_df = spark.read.format(file_type)\\\n",
    ".option(\"header\", first_row_is_header)\\\n",
    ".option(\"sep\", delimiter)\\\n",
    ".load(\"/FileStore/tables/authentication_credentials.csv\")\n",
    "\n",
    "# Get the AWS access key and secret key from the spark dataframe\n",
    "ACCESS_KEY = aws_keys_df.where(col('User name')=='databricks-user').select('Access key ID').collect()[0]['Access key ID']\n",
    "SECRET_KEY = aws_keys_df.where(col('User name')=='databricks-user').select('Secret access key').collect()[0]['Secret access key']\n",
    "# Encode the secrete key\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48d4d575-5a31-4126-b536-b0eb7c731b05",
     "showTitle": true,
     "title": "Mount S3"
    }
   },
   "outputs": [],
   "source": [
    "# AWS S3 bucket name\n",
    "AWS_S3_BUCKET = \"user-12853887c065-bucket\"\n",
    "# Mount name for the bucket\n",
    "MOUNT_NAME = \"/mnt/mount_name\"\n",
    "# Source url\n",
    "SOURCE_URL = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AWS_S3_BUCKET)\n",
    "# Mount the drive\n",
    "#dbutils are not supported outside of databricks notebook\n",
    "dbutils.fs.mount(SOURCE_URL, MOUNT_NAME) # RUN ONCE ONLY!\n",
    "\n",
    "display(dbutils.fs.ls(\"/mnt/mount_name/topics/12853887c065.geo/partition=0/\"))\n",
    "\n",
    "dbutils.fs.unmount(\"/mnt/mount_name\") #unmount if it is already mounted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop config and streaming from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a8b8bfc-f86d-4fd7-91a3-11596a74a85c",
     "showTitle": true,
     "title": "Hadoop config and streaming from S3"
    }
   },
   "outputs": [],
   "source": [
    "# Adding the packages required to get data from S3  \n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages com.amazonaws:aws-java-sdk-s3:1.12.490,org.apache.hadoop:hadoop-aws:3.3.1 pyspark-shell\"\n",
    "\n",
    "# Configure the hadoop setting to read from the S3 bucket\n",
    "hadoopConf.set('fs.s3a.access.key', ACCESS_KEY)\n",
    "hadoopConf.set('fs.s3a.secret.key', SECRET_KEY)\n",
    "hadoopConf.set('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider') # Allows the package to authenticate with AWS\n",
    "\n",
    "# Stream from the S3 bucket\n",
    "s3_bucket_url = \"s3n://user-12853887c065-bucket/topics/12853887c065\"\n",
    "extension = \"/partition=0/12853887c065\"\n",
    "while True:\n",
    "    df_pin = spark.read.json(f\"{s3_bucket_url}.pin{extension}.pin+0+*.json\")\n",
    "    df_geo = spark.read.json(f\"{s3_bucket_url}.geo{extension}.geo+0+*.json\")\n",
    "    df_user = spark.read.json(f\"{s3_bucket_url}.user{extension}.user+0+*.json\")\n",
    "    df_pin.show(5, True)\n",
    "    df_geo.show(5, True)\n",
    "    df_user.show(5, True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2023-06-18 14:01:25",
   "widgets": {}
  },
  "interpreter": {
   "hash": "5ab6cb1f5c7dfb9724c34bd82b58dded0b44f6750f81d47867e6b3ef07c3b88e"
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 ('pinterest_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
